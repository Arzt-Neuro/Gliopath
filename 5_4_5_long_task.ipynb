{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## this sample script takes continuous variable as outcome, as example",
   "id": "37b42d98c88e2399"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-21T11:50:57.049880Z",
     "start_time": "2025-10-21T11:50:37.449490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gliopath.train.task.long import seed_torch, train, EmbeddingDataset, TaskHead, collate_fn_with_padding, SeriesHead\n",
    "from gliopath.utils.proces import split_dataset\n",
    "from gliopath.train.gadget import get_sampler\n",
    "\n",
    "os.chdir('F:/workspace/pathology/gigapath')\n",
    "# os.chdir('/mnt/f/workspace/pathology/gigapath')"
   ],
   "id": "8a0d9e3ad9ebd3c5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T11:50:57.084625Z",
     "start_time": "2025-10-21T11:50:57.064892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 42\n",
    "dataset_df = pd.read_table('data\\\\metadata.tbl', sep='\\t')\n",
    "test_df = pd.read_table('data\\\\metadata_test.tbl', sep='\\t')\n",
    "embed_path = 'output/tiles/rand_embed/'\n",
    "z_score = False\n",
    "outcome_col = ['IDH1','TP53','ATRX','PTEN','EGFR','TERT']\n",
    "num_classes = len(outcome_col)\n",
    "batch_size = 4\n",
    "num_workers = 0\n",
    "embed_dim = 1536\n",
    "weighted_sampler = True\n",
    "feat_layers=[0,1,2]\n",
    "num_epochs = 1\n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "split_col = 'split_col'\n",
    "id_col = 'id'\n",
    "params = {\n",
    "    'lr': 0.001,\n",
    "    'min_lr': 0.0,\n",
    "    'num_epochs': num_epochs,\n",
    "    'eval_interval': 10,\n",
    "    'output_dir': 'output/models/life',\n",
    "    'optim': 'sgd',\n",
    "    'weight_decay': 0.01,\n",
    "    'outcome_type': 'cat',\n",
    "    'gc_step': 10,\n",
    "    'freeze_longnet': True,\n",
    "}"
   ],
   "id": "b57347f51dcd498e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T11:50:59.062277Z",
     "start_time": "2025-10-21T11:50:57.483575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set the random seed\n",
    "seed_torch(torch.device('cuda'), 0)\n",
    "# read the metadata\n",
    "dataset_df = split_dataset(dataset_df, id_col='id', type_col='tumour_type', val_split=0.2, test_split=0, in_df=True, split_col='split_col')\n",
    "test_df['split_col'] = 'test'\n",
    "dataset_df = pd.concat([dataset_df, test_df], ignore_index=True)\n",
    "\n",
    "# load the dataset\n",
    "train_dataset, val_dataset, test_dataset = [EmbeddingDataset(dataset_df, embed_path, feat_layer=feat_layers, split_col=split_col, split=split, id_col=id_col, type_col=outcome_col, outcome_type='gene', z_score=z_score) for split in splits]\n",
    "\n",
    "# set num_classes\n",
    "print(f'Sample size:\\nTrain: {len(train_dataset)}\\tVal: {len(val_dataset)}\\tTest: {len(test_dataset)}')"
   ],
   "id": "6e94cb28f7b9fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sample_data = torch.load(path)\n",
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sample_data = torch.load(path)\n",
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sample_data = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:\n",
      "Train: 158\tVal: 42\tTest: 50\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T11:50:59.090331Z",
     "start_time": "2025-10-21T11:50:59.083150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# infinite sampler for training\n",
    "# not sure if cha nge shuffle to TRUE? (*)\n",
    "# train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset, replacement=True)\n",
    "train_sampler = get_sampler(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn_with_padding, sampler=train_sampler, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn_with_padding, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn_with_padding, pin_memory=True)"
   ],
   "id": "c33c757f5f0e3c66",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T11:51:14.469069Z",
     "start_time": "2025-10-21T11:50:59.128431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set the model\n",
    "import timm\n",
    "import gliopath.models.longn\n",
    "from gliopath.models.load import giga_slide_enc\n",
    "model_longnet = giga_slide_enc(path='model/pub/slide_encoder.pth', global_pool=True)\n",
    "model = SeriesHead(LongNetModel=model_longnet,\n",
    "                   TaskHead=TaskHead(768 * len(feat_layers), num_classes),\n",
    "                   feat_layers=feat_layers)"
   ],
   "id": "d8d90b77c7d3543e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\conda\\gliopath\\Lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "F:\\conda\\gliopath\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\workspace\\pathology\\gigapath\n",
      "dilated_ratio:  [1, 2, 4, 8, 16]\n",
      "segment_length:  [np.int64(1024), np.int64(5792), np.int64(32768), np.int64(185363), np.int64(1048576)]\n",
      "Number of trainable LongNet parameters:  85148160\n",
      "Global Pooling: True\n",
      "\u001B[93m Pretrained weights not found at local-dir:model/pub/slide_encoder.pth. Randomly initialized the model! \u001B[00m\n",
      "Slide encoder param # 86330880\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:46:47.608161Z",
     "start_time": "2025-10-21T05:46:47.600794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SeriesHead(LongNetModel=model_longnet,\n",
    "                   TaskHead=TaskHead(768 * len(feat_layers), num_classes),\n",
    "                   feat_layers=feat_layers)"
   ],
   "id": "cd5b14d3a8814360",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:24:49.356653Z",
     "start_time": "2025-10-21T05:24:49.351072Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.nn as nn",
   "id": "9bf595e48dbe391f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:24:49.561605Z",
     "start_time": "2025-10-21T05:24:49.555063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "total_loss = 0"
   ],
   "id": "7b9aafe51e560a7b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:24:49.848060Z",
     "start_time": "2025-10-21T05:24:49.736401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred_gather, category_gather = [], []\n",
    "for _, batch in enumerate(val_loader):\n",
    "    embed, coords, category = batch['tile_embeds'].to(device), batch['coords'].to(device), batch[\n",
    "        'categories'].to(device)\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = model(embeddings=embed, coords=coords)\n",
    "        loss = criterion(output, category)\n",
    "        total_loss += loss.item()\n",
    "    # gather the predictions and categories\n",
    "    pred_gather.append(output.cpu().numpy())\n",
    "    category_gather.append(category.cpu().numpy())\n",
    "    break"
   ],
   "id": "b3c3e2a850e60d30",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ge Yi-Lun\\AppData\\Local\\Temp\\ipykernel_4332\\1005242074.py:5: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m     total_loss += loss.item()\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# gather the predictions and categories\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m pred_gather.append(\u001B[43moutput\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     11\u001B[39m category_gather.append(category.cpu().numpy())\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:25:27.264765Z",
     "start_time": "2025-10-21T05:25:27.250813Z"
    }
   },
   "cell_type": "code",
   "source": "embed",
   "id": "829b59c3a1da11c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.4078e-01,  1.1254e+00, -2.6722e-01,  ...,  1.6076e+00,\n",
       "           1.3396e+00,  3.3181e-01],\n",
       "         [ 7.1748e-01,  4.8242e-01,  1.8288e-01,  ..., -2.4936e-01,\n",
       "          -7.7294e-01,  1.2160e-01],\n",
       "         [-1.0970e+00,  1.5350e+00,  2.0763e-01,  ...,  9.6836e-03,\n",
       "          -1.1984e+00, -5.4515e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.4068e-01,  2.0757e+00, -7.5122e-01,  ...,  2.4497e+00,\n",
       "           5.4724e-01, -2.9873e-02],\n",
       "         [ 1.2084e+00,  7.6544e-01, -2.5682e-01,  ..., -7.0432e-02,\n",
       "           1.9836e-01,  6.4339e-01],\n",
       "         [ 3.8106e-01,  4.5143e-01,  2.2973e-01,  ...,  7.2868e-01,\n",
       "           1.8203e+00, -1.6289e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.4271e+00, -4.0236e-01,  1.2797e+00,  ..., -2.1921e-01,\n",
       "           4.9641e-01, -8.6563e-01],\n",
       "         [-3.1636e-01,  1.1339e-01, -2.9629e-01,  ...,  1.4076e+00,\n",
       "          -7.2471e-01,  1.2213e-01],\n",
       "         [-9.0088e-01,  3.4156e-01,  1.3833e+00,  ..., -1.5457e-01,\n",
       "           1.5997e+00, -1.8632e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.9936e+00, -1.4023e+00, -6.1845e-02,  ..., -1.1935e-01,\n",
       "          -1.3753e+00, -1.6055e-01],\n",
       "         [-4.0918e-01,  4.2630e-02,  4.2748e-01,  ..., -5.8569e-01,\n",
       "          -9.5771e-01, -2.9567e-02],\n",
       "         [ 1.9740e-01,  6.9549e-01, -5.5812e-02,  ..., -1.0638e+00,\n",
       "          -9.3110e-01,  4.1523e-01],\n",
       "         ...,\n",
       "         [-2.6858e-01,  7.6699e-01,  1.3174e+00,  ..., -1.4646e+00,\n",
       "          -1.2587e+00, -1.0421e-03],\n",
       "         [ 3.1701e-01, -1.8514e+00, -8.5161e-01,  ..., -9.9082e-01,\n",
       "           1.8207e+00, -9.4509e-01],\n",
       "         [ 9.9659e-02, -4.0251e-01, -1.0217e+00,  ...,  8.2826e-02,\n",
       "           6.9298e-01,  6.9802e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:33:03.315211Z",
     "start_time": "2025-10-21T05:33:03.309438Z"
    }
   },
   "cell_type": "code",
   "source": "from tqdm.notebook import tqdm",
   "id": "116bcab27ae3cf9e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:54:19.093356Z",
     "start_time": "2025-10-21T05:54:19.071410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SeriesHead(LongNetModel=model_longnet,\n",
    "                   TaskHead=TaskHead(768 * len(feat_layers), num_classes, lite=False, long=True),\n",
    "                   feat_layers=feat_layers)"
   ],
   "id": "24517096ed19ebc0",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:54:20.041535Z",
     "start_time": "2025-10-21T05:54:19.641141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "total_loss = 0.0\n",
    "num_batches = 0\n",
    "gc_step = 1\n",
    "for param in model.longnetmodel.parameters():\n",
    "    param.requires_grad = False\n",
    "param_groups = [\n",
    "    {'params': list(model.taskhead.parameters()), 'lr': 0.0001}\n",
    "]\n",
    "optimizer = torch.optim.Adam(param_groups, weight_decay=0.0001)\n",
    "optimizer.zero_grad()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "    embed, coords, category = batch['tile_embeds'].to(device), batch['coords'].to(device), batch['categories'].to(device)\n",
    "\n",
    "    # Regular training\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = model(embeddings=embed[:,:200,:], coords=coords[:,:200,:])\n",
    "        loss = loss_fn(output, category)\n",
    "        loss = loss / gc_step\n",
    "    loss.backward()\n",
    "\n",
    "    if (batch_idx + 1) % gc_step == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    total_loss += loss.item() * gc_step\n",
    "    num_batches += 1\n",
    "\n",
    "    break\n",
    "    if batch_idx>1:\n",
    "        break\n",
    "\n",
    "avg_loss = total_loss / num_batches\n"
   ],
   "id": "f086db7da268aaa8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb47ca332add4d8ca7b717183ced7e95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ge Yi-Lun\\AppData\\Local\\Temp\\ipykernel_4332\\410019691.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:52:36.712248Z",
     "start_time": "2025-10-21T05:52:36.673383Z"
    }
   },
   "cell_type": "code",
   "source": "embed = torch.where(embed == 0, torch.tensor(1e-8), embed)",
   "id": "2a44689f0851a3c2",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:52:38.197635Z",
     "start_time": "2025-10-21T05:52:37.880154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    output = model(embeddings=embed, coords=coords)\n",
    "output"
   ],
   "id": "dcfe99629f4c8d0f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ge Yi-Lun\\AppData\\Local\\Temp\\ipykernel_4332\\871105059.py:1: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:51:41.041777Z",
     "start_time": "2025-10-21T05:51:41.027710Z"
    }
   },
   "cell_type": "code",
   "source": "embed",
   "id": "c615beb4ed46b688",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1203,  0.1157, -0.3988,  ..., -0.1207, -1.1815, -1.6982],\n",
       "         [ 0.1887,  0.4822,  0.1379,  ...,  0.4477,  0.9428,  0.5185],\n",
       "         [-1.0728, -1.2576, -0.4464,  ...,  0.2475,  0.3290,  2.3571],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.5056, -0.4710,  0.6082,  ..., -0.5095,  0.7896,  0.5461],\n",
       "         [-0.4915, -0.0946, -0.9899,  ..., -0.2051,  1.1551, -0.2982],\n",
       "         [ 0.9325, -0.2584,  1.1333,  ...,  0.1947, -1.2200, -1.3275],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.3312, -0.1151,  0.9996,  ..., -0.4596, -0.2778, -0.9568],\n",
       "         [ 0.0515, -1.6681, -1.4083,  ...,  0.7773, -2.0435, -0.5956],\n",
       "         [ 0.7184,  1.5715, -1.1961,  ..., -0.0507,  0.1330,  0.8979],\n",
       "         ...,\n",
       "         [-1.3720,  0.0342, -0.3575,  ...,  1.1614,  0.1928,  1.6429],\n",
       "         [-0.8262, -0.7264, -0.4932,  ..., -0.2648,  0.3450,  0.4343],\n",
       "         [ 0.4778, -0.2539,  0.2351,  ..., -0.1313, -0.5078,  0.2455]],\n",
       "\n",
       "        [[ 0.1562, -0.8084,  0.1172,  ...,  0.3947, -0.1054, -1.0485],\n",
       "         [ 0.6603, -1.0113, -1.6368,  ..., -1.3199, -0.1473, -0.8977],\n",
       "         [-0.2206, -0.1948,  1.1508,  ...,  1.0933, -1.5922,  1.5917],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:51:03.975199Z",
     "start_time": "2025-10-21T05:51:03.956892Z"
    }
   },
   "cell_type": "code",
   "source": "embed",
   "id": "fc26715db3a993bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5879,  1.3860, -0.6725,  ...,  0.6962, -1.6394,  0.3380],\n",
       "         [ 1.4756, -0.7282,  1.3812,  ..., -0.6527, -0.5165,  1.3156],\n",
       "         [-0.0662, -0.1814,  0.2001,  ..., -0.9326, -0.1593,  0.9621],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.9276, -0.2705, -0.8283,  ...,  0.9314,  0.7463, -1.1774],\n",
       "         [ 0.9273, -0.7051, -0.6965,  ...,  1.0321, -1.1501,  0.1631],\n",
       "         [ 1.6544, -0.8149,  1.4631,  ..., -0.3226, -0.9224, -1.5511],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.6390, -0.8477,  0.9876,  ..., -0.1103, -1.3053, -0.2323],\n",
       "         [ 0.6189, -0.8792,  0.1409,  ..., -0.8380, -0.5316,  0.2132],\n",
       "         [ 1.0895, -0.3458, -2.0489,  ..., -0.2689,  0.4261,  0.0508],\n",
       "         ...,\n",
       "         [ 0.4775,  0.5041,  0.1487,  ..., -0.2584,  0.5175,  1.2019],\n",
       "         [-0.2035,  1.0855,  0.2945,  ..., -0.5119, -0.1538, -0.2669],\n",
       "         [ 0.4733,  0.7483,  0.0320,  ..., -0.2255,  0.1283, -0.8357]],\n",
       "\n",
       "        [[-1.0780,  0.6263, -0.1451,  ..., -0.5039,  1.5487,  0.9133],\n",
       "         [-1.1206,  0.6412, -2.2851,  ...,  0.6661, -0.0133,  0.3310],\n",
       "         [-0.7103, -0.9877,  0.7492,  ...,  0.2585,  0.6507,  1.0743],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:54:25.593030Z",
     "start_time": "2025-10-21T05:54:25.584811Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "7b929dd778daf6e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:43:02.968270Z",
     "start_time": "2025-10-21T05:43:02.960892Z"
    }
   },
   "cell_type": "code",
   "source": "embed.shape",
   "id": "9c0c09d41af708c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300, 1536])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:43:29.534405Z",
     "start_time": "2025-10-21T05:43:29.528626Z"
    }
   },
   "cell_type": "code",
   "source": "coords.shape",
   "id": "ef31b677d5b28ffb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:33:28.777486Z",
     "start_time": "2025-10-21T05:33:28.772086Z"
    }
   },
   "cell_type": "code",
   "source": "batch_idx",
   "id": "60914d4ac403d232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:35:11.289211Z",
     "start_time": "2025-10-21T05:35:11.281932Z"
    }
   },
   "cell_type": "code",
   "source": "embed[:,:200,:].shape",
   "id": "e3c49348cef9fcc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200, 1536])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:51:21.082944Z",
     "start_time": "2025-10-21T05:51:20.842146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    output = model(embeddings=embed[:,:10,:], coords=coords[:,:10,:])\n",
    "output"
   ],
   "id": "53c18bf7c3fa2db4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ge Yi-Lun\\AppData\\Local\\Temp\\ipykernel_4332\\470183074.py:1: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:34:37.054052Z",
     "start_time": "2025-10-21T05:34:37.046460Z"
    }
   },
   "cell_type": "code",
   "source": "embed.shape",
   "id": "49eb14e965cb0572",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 282, 1536])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:34:17.954440Z",
     "start_time": "2025-10-21T05:34:17.938574Z"
    }
   },
   "cell_type": "code",
   "source": "coords",
   "id": "bdde0f91adcd0f56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  3072., 182656.],\n",
       "         [  3072.,  47232.],\n",
       "         [  3072., 107648.],\n",
       "         ...,\n",
       "         [     0.,      0.],\n",
       "         [     0.,      0.],\n",
       "         [     0.,      0.]],\n",
       "\n",
       "        [[  3072.,  17792.],\n",
       "         [  3072.,  82560.],\n",
       "         [  3072.,  46208.],\n",
       "         ...,\n",
       "         [     0.,      0.],\n",
       "         [     0.,      0.],\n",
       "         [     0.,      0.]],\n",
       "\n",
       "        [[  3072., 180096.],\n",
       "         [  3072., 119424.],\n",
       "         [  3072., 209536.],\n",
       "         ...,\n",
       "         [     0.,      0.],\n",
       "         [     0.,      0.],\n",
       "         [     0.,      0.]],\n",
       "\n",
       "        [[  3072., 232320.],\n",
       "         [  3072.,  67456.],\n",
       "         [  3072., 235392.],\n",
       "         ...,\n",
       "         [  3072.,  61568.],\n",
       "         [  3072.,  80000.],\n",
       "         [  3072.,  95360.]]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:34:13.844835Z",
     "start_time": "2025-10-21T05:34:13.830963Z"
    }
   },
   "cell_type": "code",
   "source": "embed",
   "id": "3f775d0fe2ce1768",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1935, -1.4096,  0.3916,  ..., -0.6122, -2.1608,  0.1298],\n",
       "         [ 0.7913, -0.0469,  0.1334,  ..., -0.8014,  0.6772, -1.1878],\n",
       "         [-0.3871,  2.1709,  1.3291,  ..., -0.4214, -0.3425,  0.6355],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-3.4571, -1.1231,  1.0056,  ...,  0.9908,  2.0672,  0.0549],\n",
       "         [-1.2838, -0.4897,  0.8906,  ..., -0.7166, -0.1174, -0.4543],\n",
       "         [ 0.6704, -0.3541,  0.7100,  ..., -1.7715, -1.1464, -1.3441],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0729, -0.0437, -1.6062,  ...,  0.0264, -0.2498,  1.2771],\n",
       "         [ 1.1751, -0.0650, -0.3351,  ..., -0.1114, -0.6384,  0.3763],\n",
       "         [-0.2639,  1.4857,  0.6137,  ...,  0.3492,  0.9494, -1.1121],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4397,  0.4170,  1.3240,  ..., -1.0239,  1.6869, -2.4826],\n",
       "         [-0.3167, -0.1003, -0.5730,  ..., -0.0893, -0.2090, -0.1544],\n",
       "         [-0.7069, -0.7350, -0.8753,  ...,  0.9410, -0.2656, -0.1066],\n",
       "         ...,\n",
       "         [-0.0931,  0.7753,  1.4319,  ...,  1.9957, -0.4722, -0.4928],\n",
       "         [-1.2745,  0.2898,  0.6133,  ..., -1.7937, -1.5185, -0.8050],\n",
       "         [-0.8648, -0.0531, -0.0239,  ..., -0.9776, -0.1487,  0.3360]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:34:04.730674Z",
     "start_time": "2025-10-21T05:34:04.717450Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "26b95a225ca18b9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:33:57.878698Z",
     "start_time": "2025-10-21T05:33:57.871792Z"
    }
   },
   "cell_type": "code",
   "source": "total_loss",
   "id": "fb558762743814e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T05:44:40.584932Z",
     "start_time": "2025-10-21T05:44:40.107085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "pred_gather, target_gather = train(model, train_loader, val_loader, test_loader, **params)"
   ],
   "id": "abb5cd169086242c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LongNet encoder has been frozen\n",
      "Set the optimizer as sgd\n",
      "Start training for 1 epochs with gradient accumulation steps: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a509b4bd83b549d882f80748d3fb4a9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 0:   0%|          | 0/40 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37ed6b4ecd0b45f4968889f98e4036c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x2304 and 96x6)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[55]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m pred_gather, target_gather = \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:750\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(model, train_loader, val_loader, test_loader, num_epochs, lr, min_lr, optim, weight_decay, output_dir, eval_interval, momentum, model_select, outcome_type, gc_step, use_fp16, freeze_longnet, longnet_lr_factor)\u001B[39m\n\u001B[32m    746\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mStart training for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m epochs with gradient accumulation steps: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgc_step\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m    748\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(num_epochs)):\n\u001B[32m    749\u001B[39m     \u001B[38;5;66;03m# Train one epoch\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m750\u001B[39m     avg_loss = \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp16_scaler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    751\u001B[39m \u001B[43m                           \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgc_step\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    753\u001B[39m     current_lr = optimizer.param_groups[\u001B[32m0\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m    754\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mEpoch [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[33mTrain Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[33mLR: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_lr\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.6f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:477\u001B[39m, in \u001B[36mtrain_epoch\u001B[39m\u001B[34m(train_loader, model, fp16_scaler, optimizer, loss_fn, epoch, device, gc_step)\u001B[39m\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    475\u001B[39m     \u001B[38;5;66;03m# Regular training\u001B[39;00m\n\u001B[32m    476\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m torch.cuda.amp.autocast():\n\u001B[32m--> \u001B[39m\u001B[32m477\u001B[39m         output = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoords\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcoords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    478\u001B[39m         loss = loss_fn(output, category)\n\u001B[32m    479\u001B[39m         loss = loss / gc_step\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\conda\\gliopath\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\conda\\gliopath\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:58\u001B[39m, in \u001B[36mSeriesHead.forward\u001B[39m\u001B[34m(self, embeddings, coords)\u001B[39m\n\u001B[32m     55\u001B[39m     embed = (embed - embed.mean()) / embed.std()\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# Pass through task head\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m embed = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtaskhead\u001B[49m\u001B[43m(\u001B[49m\u001B[43membed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m embed\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\conda\\gliopath\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\conda\\gliopath\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\long.py:284\u001B[39m, in \u001B[36mTaskHead.forward\u001B[39m\u001B[34m(self, embeddings)\u001B[39m\n\u001B[32m    283\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, embeddings):\n\u001B[32m--> \u001B[39m\u001B[32m284\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfc\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\conda\\gliopath\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\conda\\gliopath\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\conda\\gliopath\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (4x2304 and 96x6)"
     ]
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
