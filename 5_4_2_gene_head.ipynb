{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gliopath.train.task.gene import seed_torch, train, EmbeddingDataset, TaskHead\n",
    "from gliopath.utils.proces import split_dataset\n",
    "\n",
    "os.chdir('F:/workspace/pathology/gigapath')"
   ],
   "id": "4b9d10788093da7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T13:45:05.498272Z",
     "start_time": "2025-09-23T13:45:05.488378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 42\n",
    "dataset_df = pd.read_table('data\\\\metadata.tbl', sep='\\t')\n",
    "embed_path = 'output/all_slides_embeds.pt'\n",
    "z_score = False\n",
    "gene_col = ['IDH1','TP53','ATRX','PTEN','EGFR','TERT']\n",
    "num_classes = len(gene_col)\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "embed_dim = 1536\n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "split_col = 'split_col'\n",
    "id_col = 'id'\n",
    "params = {\n",
    "    'lr': 0.02,\n",
    "    'min_lr': 0.0,\n",
    "    'train_iters': 4000,\n",
    "    'eval_interval': 100,\n",
    "    'output_dir': 'output/models/gene',\n",
    "    'optim': 'sgd',\n",
    "    'weight_decay': 0.01,\n",
    "}"
   ],
   "id": "f7bfa35f5486d4c7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T13:45:05.574660Z",
     "start_time": "2025-09-23T13:45:05.536263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set the random seed\n",
    "seed_torch(torch.device('cuda'), 0)\n",
    "# read the metadata\n",
    "dataset_df = split_dataset(dataset_df, id_col='id', type_col='tumour_type', val_split=0.2, test_split=0.1, in_df=True, split_col='split_col')\n",
    "\n",
    "# load the dataset\n",
    "train_dataset, val_dataset, test_dataset = [EmbeddingDataset(dataset_df, embed_path, split_col=split_col, split=split, id_col=id_col, type_col=gene_col, z_score=z_score) for split in splits]\n",
    "# set num_classes\n",
    "print(f'Sample size:\\nTrain: {len(train_dataset)}\\tVal: {len(val_dataset)}\\tTest: {len(test_dataset)}')"
   ],
   "id": "3c2d36f1e8c910b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:\n",
      "Train: 68\tVal: 20\tTest: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\gene.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  collated_dict = torch.load(self.embed_path)\n",
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\gene.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  collated_dict = torch.load(self.embed_path)\n",
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\gene.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  collated_dict = torch.load(self.embed_path)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T13:45:05.598715Z",
     "start_time": "2025-09-23T13:45:05.591812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# infinite sampler for training\n",
    "train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset, replacement=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, sampler=train_sampler, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# Load the model\n",
    "model = TaskHead(embed_dim, num_classes)"
   ],
   "id": "52709e193f45f551",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T13:48:43.823474Z",
     "start_time": "2025-09-23T13:45:09.282164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "train(model, train_loader, val_loader, test_loader, **params)"
   ],
   "id": "ef3b4603527e957c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the optimizer as sgd\n",
      "Start training\n",
      "Iteration [9/4000]\tLoss: 0.6599343419075012\tLR: 0.0199996915764479\n",
      "Iteration [19/4000]\tLoss: 0.6316266655921936\tLR: 0.01999876632481661\n",
      "Iteration [29/4000]\tLoss: 0.6054642200469971\tLR: 0.01999722430218001\n",
      "Iteration [39/4000]\tLoss: 0.5812366008758545\tLR: 0.01999506560365732\n",
      "Iteration [49/4000]\tLoss: 0.5587648749351501\tLR: 0.019992290362407236\n",
      "Iteration [59/4000]\tLoss: 0.5378857851028442\tLR: 0.01998889874961971\n",
      "Iteration [69/4000]\tLoss: 0.5184516310691833\tLR: 0.01998489097450538\n",
      "Iteration [79/4000]\tLoss: 0.5003296136856079\tLR: 0.019980267284282715\n",
      "Iteration [89/4000]\tLoss: 0.48340025544166565\tLR: 0.019975027964162704\n",
      "Iteration [99/4000]\tLoss: 0.46755653619766235\tLR: 0.019969173337331274\n",
      "Start evaluating ...\n",
      "Val [99/4000] Accuracy: 0.5 f1: 0.21364522417153997 Precision: 0.36904761904761907 Recall: 0.18686868686868688 AUROC: 0.45749579124579126 AUPRC: 0.5809939472608442\n",
      "Best f1 increase from 0 to 0.21364522417153997\n",
      "Iteration [109/4000]\tLoss: 0.45270273089408875\tLR: 0.019962703764929406\n",
      "Iteration [119/4000]\tLoss: 0.43875306844711304\tLR: 0.019955619646030796\n",
      "Iteration [129/4000]\tLoss: 0.42563074827194214\tLR: 0.019947921417617264\n",
      "Iteration [139/4000]\tLoss: 0.41326695680618286\tLR: 0.019939609554551794\n",
      "Iteration [149/4000]\tLoss: 0.4015999734401703\tLR: 0.019930684569549256\n",
      "Iteration [159/4000]\tLoss: 0.3905743360519409\tLR: 0.019921147013144777\n",
      "Iteration [169/4000]\tLoss: 0.3801400661468506\tLR: 0.019910997473659754\n",
      "Iteration [179/4000]\tLoss: 0.3702521026134491\tLR: 0.019900236577165577\n",
      "Iteration [189/4000]\tLoss: 0.3608698844909668\tLR: 0.019888864987445055\n",
      "Iteration [199/4000]\tLoss: 0.3519565463066101\tLR: 0.019876883405951378\n",
      "Start evaluating ...\n",
      "Val [199/4000] Accuracy: 0.5083333333333333 f1: 0.25594405594405595 Precision: 0.3442760942760943 Recall: 0.23383838383838382 AUROC: 0.4894991582491583 AUPRC: 0.6009785108338659\n",
      "Best f1 increase from 0.21364522417153997 to 0.25594405594405595\n",
      "Iteration [209/4000]\tLoss: 0.343478798866272\tLR: 0.019864292571764953\n",
      "Iteration [219/4000]\tLoss: 0.33540621399879456\tLR: 0.01985109326154774\n",
      "Iteration [229/4000]\tLoss: 0.3277112543582916\tLR: 0.019837286289495357\n",
      "Iteration [239/4000]\tLoss: 0.32036876678466797\tLR: 0.019822872507286884\n",
      "Iteration [249/4000]\tLoss: 0.3133557438850403\tLR: 0.019807852804032296\n",
      "Iteration [259/4000]\tLoss: 0.30665114521980286\tLR: 0.019792228106217655\n",
      "Iteration [269/4000]\tLoss: 0.30023565888404846\tLR: 0.019775999377647905\n",
      "Iteration [279/4000]\tLoss: 0.2940916121006012\tLR: 0.01975916761938747\n",
      "Iteration [289/4000]\tLoss: 0.2882026433944702\tLR: 0.019741733869698488\n",
      "Iteration [299/4000]\tLoss: 0.2825537621974945\tLR: 0.019723699203976753\n",
      "Start evaluating ...\n",
      "Val [299/4000] Accuracy: 0.5166666666666667 f1: 0.3091269841269841 Precision: 0.3796296296296296 Recall: 0.28754208754208754 AUROC: 0.4877272727272728 AUPRC: 0.5950394347485909\n",
      "Best f1 increase from 0.25594405594405595 to 0.3091269841269841\n",
      "Iteration [309/4000]\tLoss: 0.2771311402320862\tLR: 0.019705064734685408\n",
      "Iteration [319/4000]\tLoss: 0.271921843290329\tLR: 0.019685831611286297\n",
      "Iteration [329/4000]\tLoss: 0.2669140696525574\tLR: 0.01966600102016906\n",
      "Iteration [339/4000]\tLoss: 0.2620967924594879\tLR: 0.01964557418457797\n",
      "Iteration [349/4000]\tLoss: 0.2574597895145416\tLR: 0.01962455236453647\n",
      "Iteration [359/4000]\tLoss: 0.25299352407455444\tLR: 0.019602936856769424\n",
      "Iteration [369/4000]\tLoss: 0.2486891895532608\tLR: 0.019580728994623188\n",
      "Iteration [379/4000]\tLoss: 0.24453851580619812\tLR: 0.019557930147983293\n",
      "Iteration [389/4000]\tLoss: 0.24053379893302917\tLR: 0.019534541723190003\n",
      "Iteration [399/4000]\tLoss: 0.23666787147521973\tLR: 0.019510565162951528\n",
      "Start evaluating ...\n",
      "Val [399/4000] Accuracy: 0.5 f1: 0.30689245395127746 Precision: 0.3568653568653568 Recall: 0.30269360269360274 AUROC: 0.4893771043771044 AUPRC: 0.5885841537259452\n",
      "Iteration [409/4000]\tLoss: 0.23293395340442657\tLR: 0.01948600194625504\n",
      "Iteration [419/4000]\tLoss: 0.22932572662830353\tLR: 0.01946085358827545\n",
      "Iteration [429/4000]\tLoss: 0.2258373349905014\tLR: 0.019435121640281928\n",
      "Iteration [439/4000]\tLoss: 0.22246316075325012\tLR: 0.019408807689542246\n",
      "Iteration [449/4000]\tLoss: 0.219198077917099\tLR: 0.01938191335922483\n",
      "Iteration [459/4000]\tLoss: 0.2160370796918869\tLR: 0.01935444030829866\n",
      "Iteration [469/4000]\tLoss: 0.2129756361246109\tLR: 0.019326390231430925\n",
      "Iteration [479/4000]\tLoss: 0.2100093513727188\tLR: 0.019297764858882495\n",
      "Iteration [489/4000]\tLoss: 0.20713414251804352\tLR: 0.019268565956401185\n",
      "Iteration [499/4000]\tLoss: 0.20434609055519104\tLR: 0.01923879532511285\n",
      "Start evaluating ...\n",
      "Val [499/4000] Accuracy: 0.48333333333333334 f1: 0.3160348423506318 Precision: 0.33702408702408704 Recall: 0.31936026936026934 AUROC: 0.4911658249158249 AUPRC: 0.5943131233627431\n",
      "Best f1 increase from 0.3091269841269841 to 0.3160348423506318\n",
      "Iteration [509/4000]\tLoss: 0.20164157450199127\tLR: 0.019208454801410247\n",
      "Iteration [519/4000]\tLoss: 0.19901713728904724\tLR: 0.019177546256839793\n",
      "Iteration [529/4000]\tLoss: 0.1964695155620575\tLR: 0.019146071597986116\n",
      "Iteration [539/4000]\tLoss: 0.19399558007717133\tLR: 0.01911403276635443\n",
      "Iteration [549/4000]\tLoss: 0.19159239530563354\tLR: 0.019081431738250793\n",
      "Iteration [559/4000]\tLoss: 0.1892572045326233\tLR: 0.01904827052466017\n",
      "Iteration [569/4000]\tLoss: 0.18698734045028687\tLR: 0.01901455117112243\n",
      "Iteration [579/4000]\tLoss: 0.1847803145647049\tLR: 0.018980275757606135\n",
      "Iteration [589/4000]\tLoss: 0.18263371288776398\tLR: 0.018945446398380233\n",
      "Iteration [599/4000]\tLoss: 0.18054528534412384\tLR: 0.01891006524188367\n",
      "Start evaluating ...\n",
      "Val [599/4000] Accuracy: 0.475 f1: 0.3160348423506318 Precision: 0.33702408702408704 Recall: 0.31936026936026934 AUROC: 0.5013194444444444 AUPRC: 0.6014883630951723\n",
      "Iteration [609/4000]\tLoss: 0.17851288616657257\tLR: 0.018874134470592833\n",
      "Iteration [619/4000]\tLoss: 0.17653442919254303\tLR: 0.018837656300886928\n",
      "Iteration [629/4000]\tLoss: 0.1746080070734024\tLR: 0.018800632982911316\n",
      "Iteration [639/4000]\tLoss: 0.1727316975593567\tLR: 0.018763066800438627\n",
      "Iteration [649/4000]\tLoss: 0.1709037572145462\tLR: 0.018724960070727964\n",
      "Iteration [659/4000]\tLoss: 0.16912250220775604\tLR: 0.018686315144381904\n",
      "Iteration [669/4000]\tLoss: 0.1673862636089325\tLR: 0.01864713440520154\n",
      "Iteration [679/4000]\tLoss: 0.16569355130195618\tLR: 0.018607420270039428\n",
      "Iteration [689/4000]\tLoss: 0.16404284536838531\tLR: 0.01856717518865049\n",
      "Iteration [699/4000]\tLoss: 0.1624327450990677\tLR: 0.01852640164354091\n",
      "Start evaluating ...\n",
      "Val [699/4000] Accuracy: 0.475 f1: 0.3322287933271915 Precision: 0.34819624819624817 Recall: 0.3378787878787879 AUROC: 0.4945496632996633 AUPRC: 0.5990308532847214\n",
      "Best f1 increase from 0.3160348423506318 to 0.3322287933271915\n",
      "Iteration [709/4000]\tLoss: 0.16086189448833466\tLR: 0.018485102149815025\n",
      "Iteration [719/4000]\tLoss: 0.15932902693748474\tLR: 0.018443279255020137\n",
      "Iteration [729/4000]\tLoss: 0.15783287584781647\tLR: 0.0184009355389894\n",
      "Iteration [739/4000]\tLoss: 0.15637221932411194\tLR: 0.018358073613682684\n",
      "Iteration [749/4000]\tLoss: 0.1549459993839264\tLR: 0.01831469612302543\n",
      "Iteration [759/4000]\tLoss: 0.1535530686378479\tLR: 0.0182708057427456\n",
      "Iteration [769/4000]\tLoss: 0.1521923989057541\tLR: 0.01822640518020858\n",
      "Iteration [779/4000]\tLoss: 0.15086299180984497\tLR: 0.01818149717425022\n",
      "Iteration [789/4000]\tLoss: 0.14956384897232056\tLR: 0.018136084495007858\n",
      "Iteration [799/4000]\tLoss: 0.1482941061258316\tLR: 0.018090169943749464\n",
      "Start evaluating ...\n",
      "Val [799/4000] Accuracy: 0.475 f1: 0.3322287933271915 Precision: 0.34819624819624817 Recall: 0.3378787878787879 AUROC: 0.48944654882154887 AUPRC: 0.595054582641784\n",
      "Iteration [809/4000]\tLoss: 0.1470528095960617\tLR: 0.018043756352700835\n",
      "Iteration [819/4000]\tLoss: 0.1458391398191452\tLR: 0.017996846584870902\n",
      "Iteration [829/4000]\tLoss: 0.14465227723121643\tLR: 0.017949443533875096\n",
      "Iteration [839/4000]\tLoss: 0.1434914469718933\tLR: 0.0179015501237569\n",
      "Iteration [849/4000]\tLoss: 0.142355814576149\tLR: 0.017853169308807443\n",
      "Iteration [859/4000]\tLoss: 0.14124473929405212\tLR: 0.017804304073383292\n",
      "Iteration [869/4000]\tLoss: 0.14015747606754303\tLR: 0.01775495743172234\n",
      "Iteration [879/4000]\tLoss: 0.1390933245420456\tLR: 0.01770513242775789\n",
      "Iteration [889/4000]\tLoss: 0.13805167376995087\tLR: 0.01765483213493088\n",
      "Iteration [899/4000]\tLoss: 0.13703186810016632\tLR: 0.017604059656000304\n",
      "Start evaluating ...\n",
      "Val [899/4000] Accuracy: 0.475 f1: 0.3322287933271915 Precision: 0.34819624819624817 Recall: 0.3378787878787879 AUROC: 0.48434343434343435 AUPRC: 0.5931456119828132\n",
      "Iteration [909/4000]\tLoss: 0.1360333263874054\tLR: 0.01755281812285183\n",
      "Iteration [919/4000]\tLoss: 0.13505542278289795\tLR: 0.017501110696304598\n",
      "Iteration [929/4000]\tLoss: 0.134097620844841\tLR: 0.017448940565916223\n",
      "Iteration [939/4000]\tLoss: 0.13315936923027039\tLR: 0.017396310949786102\n",
      "Iteration [949/4000]\tLoss: 0.1322401463985443\tLR: 0.017343225094356863\n",
      "Iteration [959/4000]\tLoss: 0.131339430809021\tLR: 0.01728968627421412\n",
      "Iteration [969/4000]\tLoss: 0.13045674562454224\tLR: 0.017235697791884497\n",
      "Iteration [979/4000]\tLoss: 0.12959161400794983\tLR: 0.0171812629776319\n",
      "Iteration [989/4000]\tLoss: 0.12874358892440796\tLR: 0.017126385189252063\n",
      "Iteration [999/4000]\tLoss: 0.12791219353675842\tLR: 0.017071067811865494\n",
      "Start evaluating ...\n",
      "Val [999/4000] Accuracy: 0.475 f1: 0.3322287933271915 Precision: 0.34819624819624817 Recall: 0.3378787878787879 AUROC: 0.4860269360269361 AUPRC: 0.5944316202132659\n",
      "Iteration [1009/4000]\tLoss: 0.127097025513649\tLR: 0.017015314257708573\n",
      "Iteration [1019/4000]\tLoss: 0.12629766762256622\tLR: 0.01695912796592316\n",
      "Iteration [1029/4000]\tLoss: 0.12551374733448029\tLR: 0.016902512402344385\n",
      "Iteration [1039/4000]\tLoss: 0.12474484741687775\tLR: 0.0168454710592869\n",
      "Iteration [1049/4000]\tLoss: 0.12399055808782578\tLR: 0.016788007455329428\n",
      "Iteration [1059/4000]\tLoss: 0.12325058877468109\tLR: 0.01673012513509774\n",
      "Iteration [1069/4000]\tLoss: 0.12252456694841385\tLR: 0.01667182766904601\n",
      "Iteration [1079/4000]\tLoss: 0.12181210517883301\tLR: 0.01661311865323653\n",
      "Iteration [1089/4000]\tLoss: 0.12111292779445648\tLR: 0.01655400170911795\n",
      "Iteration [1099/4000]\tLoss: 0.12042669951915741\tLR: 0.016494480483301842\n",
      "Start evaluating ...\n",
      "Val [1099/4000] Accuracy: 0.475 f1: 0.3322287933271915 Precision: 0.34819624819624817 Recall: 0.3378787878787879 AUROC: 0.4826599326599326 AUPRC: 0.5903156744306535\n",
      "Iteration [1109/4000]\tLoss: 0.11975311487913132\tLR: 0.016434558647337796\n",
      "Iteration [1119/4000]\tLoss: 0.11909185349941254\tLR: 0.01637423989748691\n",
      "Iteration [1129/4000]\tLoss: 0.11844263225793839\tLR: 0.01631352795449379\n",
      "Iteration [1139/4000]\tLoss: 0.11780520528554916\tLR: 0.016252426563357066\n",
      "Iteration [1149/4000]\tLoss: 0.11717924475669861\tLR: 0.016190939493098352\n",
      "Iteration [1159/4000]\tLoss: 0.11656451225280762\tLR: 0.016129070536529778\n",
      "Iteration [1169/4000]\tLoss: 0.11596077680587769\tLR: 0.016066823510020006\n",
      "Iteration [1179/4000]\tLoss: 0.11536774039268494\tLR: 0.016004202253258847\n",
      "Iteration [1189/4000]\tLoss: 0.11478518694639206\tLR: 0.015941210629020396\n",
      "Iteration [1199/4000]\tLoss: 0.11421287804841995\tLR: 0.015877852522924743\n",
      "Start evaluating ...\n",
      "Val [1199/4000] Accuracy: 0.4666666666666667 f1: 0.3295972143798231 Precision: 0.34264069264069263 Recall: 0.3378787878787879 AUROC: 0.48602693602693603 AUPRC: 0.5925430346125591\n",
      "Iteration [1209/4000]\tLoss: 0.11365056037902832\tLR: 0.015814131843198315\n",
      "Iteration [1219/4000]\tLoss: 0.11309806257486343\tLR: 0.015750052520432795\n",
      "Iteration [1229/4000]\tLoss: 0.1125551164150238\tLR: 0.015685618507342652\n",
      "Iteration [1239/4000]\tLoss: 0.1120215654373169\tLR: 0.015620833778521317\n",
      "Iteration [1249/4000]\tLoss: 0.11149715632200241\tLR: 0.015555702330196031\n",
      "Iteration [1259/4000]\tLoss: 0.11098170280456543\tLR: 0.015490228179981327\n",
      "Iteration [1269/4000]\tLoss: 0.11047503352165222\tLR: 0.015424415366631196\n",
      "Iteration [1279/4000]\tLoss: 0.10997696220874786\tLR: 0.015358267949789978\n",
      "Iteration [1289/4000]\tLoss: 0.10948725789785385\tLR: 0.015291790009741924\n",
      "Iteration [1299/4000]\tLoss: 0.10900580137968063\tLR: 0.015224985647159505\n",
      "Start evaluating ...\n",
      "Val [1299/4000] Accuracy: 0.4583333333333333 f1: 0.3272162619988707 Precision: 0.33809523809523806 Recall: 0.3378787878787879 AUROC: 0.4826430976430977 AUPRC: 0.5911724144919391\n",
      "Iteration [1309/4000]\tLoss: 0.1085323765873909\tLR: 0.01515785898285049\n",
      "Iteration [1319/4000]\tLoss: 0.1080668643116951\tLR: 0.015090414157503727\n",
      "Iteration [1329/4000]\tLoss: 0.10760906338691711\tLR: 0.01502265533143374\n",
      "Iteration [1339/4000]\tLoss: 0.10715881735086441\tLR: 0.014954586684324095\n",
      "Iteration [1349/4000]\tLoss: 0.10671596974134445\tLR: 0.014886212414969567\n",
      "Iteration [1359/4000]\tLoss: 0.1062803864479065\tLR: 0.014817536741017167\n",
      "Iteration [1369/4000]\tLoss: 0.1058519184589386\tLR: 0.014748563898705956\n",
      "Iteration [1379/4000]\tLoss: 0.10543041676282883\tLR: 0.014679298142605742\n",
      "Iteration [1389/4000]\tLoss: 0.10501573979854584\tLR: 0.014609743745354628\n",
      "Iteration [1399/4000]\tLoss: 0.10460776090621948\tLR: 0.014539904997395475\n",
      "Start evaluating ...\n",
      "Val [1399/4000] Accuracy: 0.4583333333333333 f1: 0.3272162619988707 Precision: 0.33809523809523806 Recall: 0.3378787878787879 AUROC: 0.4826430976430977 AUPRC: 0.5917870134318969\n",
      "Iteration [1409/4000]\tLoss: 0.10420633852481842\tLR: 0.01446978620671122\n",
      "Iteration [1419/4000]\tLoss: 0.1038113459944725\tLR: 0.01439939169855916\n",
      "Iteration [1429/4000]\tLoss: 0.10342265665531158\tLR: 0.014328725815204148\n",
      "Iteration [1439/4000]\tLoss: 0.10304015874862671\tLR: 0.014257792915650738\n",
      "Iteration [1449/4000]\tLoss: 0.10266372561454773\tLR: 0.014186597375374295\n",
      "Iteration [1459/4000]\tLoss: 0.1022932231426239\tLR: 0.0141151435860511\n",
      "Iteration [1469/4000]\tLoss: 0.10192857682704926\tLR: 0.01404343595528746\n",
      "Iteration [1479/4000]\tLoss: 0.10156963765621185\tLR: 0.013971478906347817\n",
      "Iteration [1489/4000]\tLoss: 0.10121631622314453\tLR: 0.013899276877881893\n",
      "Iteration [1499/4000]\tLoss: 0.10086850821971893\tLR: 0.013826834323650906\n",
      "Start evaluating ...\n",
      "Val [1499/4000] Accuracy: 0.4666666666666667 f1: 0.3364389233954452 Precision: 0.3418831168831169 Recall: 0.353030303030303 AUROC: 0.480959595959596 AUPRC: 0.5912423511225287\n",
      "Best f1 increase from 0.3322287933271915 to 0.3364389233954452\n",
      "Iteration [1509/4000]\tLoss: 0.1005261093378067\tLR: 0.013754155712252837\n",
      "Iteration [1519/4000]\tLoss: 0.10018901526927948\tLR: 0.013681245526846785\n",
      "Iteration [1529/4000]\tLoss: 0.09985712915658951\tLR: 0.013608108264876425\n",
      "Iteration [1539/4000]\tLoss: 0.09953036159276962\tLR: 0.01353474843779258\n",
      "Iteration [1549/4000]\tLoss: 0.09920862317085266\tLR: 0.013461170570774937\n",
      "Iteration [1559/4000]\tLoss: 0.09889179468154907\tLR: 0.013387379202452924\n",
      "Iteration [1569/4000]\tLoss: 0.09857980161905289\tLR: 0.013313378884625714\n",
      "Iteration [1579/4000]\tLoss: 0.09827256947755814\tLR: 0.013239174181981504\n",
      "Iteration [1589/4000]\tLoss: 0.09797000885009766\tLR: 0.013164769671815874\n",
      "Iteration [1599/4000]\tLoss: 0.09767202287912369\tLR: 0.013090169943749484\n",
      "Start evaluating ...\n",
      "Val [1599/4000] Accuracy: 0.4666666666666667 f1: 0.3364389233954452 Precision: 0.3418831168831169 Recall: 0.353030303030303 AUROC: 0.48432659932659927 AUPRC: 0.5923609936885397\n",
      "Iteration [1609/4000]\tLoss: 0.09737854450941086\tLR: 0.013015379599444968\n",
      "Iteration [1619/4000]\tLoss: 0.0970895066857338\tLR: 0.012940403252323051\n",
      "Iteration [1629/4000]\tLoss: 0.09680479019880295\tLR: 0.012865245527277991\n",
      "Iteration [1639/4000]\tLoss: 0.09652436524629593\tLR: 0.012789911060392302\n",
      "Iteration [1649/4000]\tLoss: 0.09624813497066498\tLR: 0.012714404498650746\n",
      "Iteration [1659/4000]\tLoss: 0.09597603231668472\tLR: 0.012638730499653736\n",
      "Iteration [1669/4000]\tLoss: 0.095707967877388\tLR: 0.012562893731329974\n",
      "Iteration [1679/4000]\tLoss: 0.09544390439987183\tLR: 0.012486898871648559\n",
      "Iteration [1689/4000]\tLoss: 0.09518375247716904\tLR: 0.012410750608330398\n",
      "Iteration [1699/4000]\tLoss: 0.09492745250463486\tLR: 0.012334453638559069\n",
      "Start evaluating ...\n",
      "Val [1699/4000] Accuracy: 0.4666666666666667 f1: 0.3364389233954452 Precision: 0.3418831168831169 Recall: 0.353030303030303 AUROC: 0.48259048821548817 AUPRC: 0.5919142750400667\n",
      "Iteration [1709/4000]\tLoss: 0.09467493742704391\tLR: 0.012258012668691051\n",
      "Iteration [1719/4000]\tLoss: 0.09442615509033203\tLR: 0.01218143241396544\n",
      "Iteration [1729/4000]\tLoss: 0.09418100863695145\tLR: 0.012104717598213067\n",
      "Iteration [1739/4000]\tLoss: 0.09393948316574097\tLR: 0.012027872953565133\n",
      "Iteration [1749/4000]\tLoss: 0.09370149672031403\tLR: 0.01195090322016129\n",
      "Iteration [1759/4000]\tLoss: 0.09346698969602585\tLR: 0.011873813145857247\n",
      "Iteration [1769/4000]\tLoss: 0.09323591738939285\tLR: 0.011796607485931927\n",
      "Iteration [1779/4000]\tLoss: 0.09300821274518967\tLR: 0.011719291002794095\n",
      "Iteration [1789/4000]\tLoss: 0.09278383105993271\tLR: 0.01164186846568863\n",
      "Iteration [1799/4000]\tLoss: 0.0925627052783966\tLR: 0.011564344650402309\n",
      "Start evaluating ...\n",
      "Val [1799/4000] Accuracy: 0.4666666666666667 f1: 0.3364389233954452 Precision: 0.3418831168831169 Recall: 0.353030303030303 AUROC: 0.48259048821548817 AUPRC: 0.5919142750400667\n",
      "Iteration [1809/4000]\tLoss: 0.09234479069709778\tLR: 0.011486724338969235\n",
      "Iteration [1819/4000]\tLoss: 0.09213003516197205\tLR: 0.011409012319375831\n",
      "Iteration [1829/4000]\tLoss: 0.09191838651895523\tLR: 0.011331213385265531\n",
      "Iteration [1839/4000]\tLoss: 0.09170981496572495\tLR: 0.011253332335643046\n",
      "Iteration [1849/4000]\tLoss: 0.09150423854589462\tLR: 0.01117537397457838\n",
      "Iteration [1859/4000]\tLoss: 0.09130164235830307\tLR: 0.011097343110910455\n",
      "Iteration [1869/4000]\tLoss: 0.09110195189714432\tLR: 0.011019244557950503\n",
      "Iteration [1879/4000]\tLoss: 0.09090515226125717\tLR: 0.010941083133185146\n",
      "Iteration [1889/4000]\tLoss: 0.09071117639541626\tLR: 0.010862863657979241\n",
      "Iteration [1899/4000]\tLoss: 0.090519979596138\tLR: 0.010784590957278456\n",
      "Start evaluating ...\n",
      "Val [1899/4000] Accuracy: 0.475 f1: 0.3494259363824581 Precision: 0.351984126984127 Recall: 0.3696969696969697 AUROC: 0.4859574915824916 AUPRC: 0.5930310594901845\n",
      "Best f1 increase from 0.3364389233954452 to 0.3494259363824581\n",
      "Iteration [1909/4000]\tLoss: 0.0903315320611\tLR: 0.010706269859311675\n",
      "Iteration [1919/4000]\tLoss: 0.09014580398797989\tLR: 0.010627905195293141\n",
      "Iteration [1929/4000]\tLoss: 0.08996272087097168\tLR: 0.010549501799124462\n",
      "Iteration [1939/4000]\tLoss: 0.08978226780891418\tLR: 0.010471064507096431\n",
      "Iteration [1949/4000]\tLoss: 0.08960440009832382\tLR: 0.01039259815759069\n",
      "Iteration [1959/4000]\tLoss: 0.08942905813455582\tLR: 0.010314107590781286\n",
      "Iteration [1969/4000]\tLoss: 0.08925624191761017\tLR: 0.010235597648336108\n",
      "Iteration [1979/4000]\tLoss: 0.0890858843922615\tLR: 0.010157073173118212\n",
      "Iteration [1989/4000]\tLoss: 0.08891797810792923\tLR: 0.01007853900888712\n",
      "Iteration [1999/4000]\tLoss: 0.08875244855880737\tLR: 0.010000000000000009\n",
      "Start evaluating ...\n",
      "Val [1999/4000] Accuracy: 0.475 f1: 0.3494259363824581 Precision: 0.351984126984127 Recall: 0.3696969696969697 AUROC: 0.4859574915824915 AUPRC: 0.584484050943176\n",
      "Iteration [2009/4000]\tLoss: 0.08858929574489594\tLR: 0.009921460991112897\n",
      "Iteration [2019/4000]\tLoss: 0.08842846006155014\tLR: 0.009842926826881801\n",
      "Iteration [2029/4000]\tLoss: 0.08826994150876999\tLR: 0.009764402351663901\n",
      "Iteration [2039/4000]\tLoss: 0.08811366558074951\tLR: 0.00968589240921872\n",
      "Iteration [2049/4000]\tLoss: 0.08795961737632751\tLR: 0.009607401842409317\n",
      "Iteration [2059/4000]\tLoss: 0.0878077819943428\tLR: 0.009528935492903576\n",
      "Iteration [2069/4000]\tLoss: 0.0876580998301506\tLR: 0.009450498200875547\n",
      "Iteration [2079/4000]\tLoss: 0.08751057088375092\tLR: 0.00937209480470687\n",
      "Iteration [2089/4000]\tLoss: 0.08736513555049896\tLR: 0.009293730140688336\n",
      "Iteration [2099/4000]\tLoss: 0.08722178637981415\tLR: 0.009215409042721553\n",
      "Start evaluating ...\n",
      "Val [2099/4000] Accuracy: 0.475 f1: 0.3494259363824581 Precision: 0.351984126984127 Recall: 0.3696969696969697 AUROC: 0.4859574915824915 AUPRC: 0.584484050943176\n",
      "Iteration [2109/4000]\tLoss: 0.0870804712176323\tLR: 0.009137136342020768\n",
      "Iteration [2119/4000]\tLoss: 0.086941197514534\tLR: 0.009058916866814854\n",
      "Iteration [2129/4000]\tLoss: 0.08680389076471329\tLR: 0.0089807554420495\n",
      "Iteration [2139/4000]\tLoss: 0.08666855841875076\tLR: 0.008902656889089545\n",
      "Iteration [2149/4000]\tLoss: 0.08653515577316284\tLR: 0.008824626025421625\n",
      "Iteration [2159/4000]\tLoss: 0.08640368282794952\tLR: 0.008746667664356956\n",
      "Iteration [2169/4000]\tLoss: 0.08627407252788544\tLR: 0.008668786614734473\n",
      "Iteration [2179/4000]\tLoss: 0.08614633977413177\tLR: 0.008590987680624171\n",
      "Iteration [2189/4000]\tLoss: 0.08602043241262436\tLR: 0.008513275661030769\n",
      "Iteration [2199/4000]\tLoss: 0.085896335542202\tLR: 0.00843565534959769\n",
      "Start evaluating ...\n",
      "Val [2199/4000] Accuracy: 0.475 f1: 0.3494259363824581 Precision: 0.351984126984127 Recall: 0.3696969696969697 AUROC: 0.4859574915824915 AUPRC: 0.5839845504436755\n",
      "Iteration [2209/4000]\tLoss: 0.0857740193605423\tLR: 0.008358131534311369\n",
      "Iteration [2219/4000]\tLoss: 0.08565347641706467\tLR: 0.008280708997205897\n",
      "Iteration [2229/4000]\tLoss: 0.08553466200828552\tLR: 0.008203392514068068\n",
      "Iteration [2239/4000]\tLoss: 0.08541756123304367\tLR: 0.008126186854142747\n",
      "Iteration [2249/4000]\tLoss: 0.08530215919017792\tLR: 0.008049096779838713\n",
      "Iteration [2259/4000]\tLoss: 0.08518844097852707\tLR: 0.007972127046434869\n",
      "Iteration [2269/4000]\tLoss: 0.08507635444402695\tLR: 0.00789528240178694\n",
      "Iteration [2279/4000]\tLoss: 0.08496589958667755\tLR: 0.00781856758603457\n",
      "Iteration [2289/4000]\tLoss: 0.0848570466041565\tLR: 0.007741987331308959\n",
      "Iteration [2299/4000]\tLoss: 0.08474978804588318\tLR: 0.007665546361440942\n",
      "Start evaluating ...\n",
      "Val [2299/4000] Accuracy: 0.475 f1: 0.3494259363824581 Precision: 0.351984126984127 Recall: 0.3696969696969697 AUROC: 0.4859574915824915 AUPRC: 0.5839845504436755\n",
      "Iteration [2309/4000]\tLoss: 0.08464407920837402\tLR: 0.007589249391669608\n",
      "Iteration [2319/4000]\tLoss: 0.08453992009162903\tLR: 0.007513101128351449\n",
      "Iteration [2329/4000]\tLoss: 0.084437295794487\tLR: 0.0074371062686700296\n",
      "Iteration [2339/4000]\tLoss: 0.08433616906404495\tLR: 0.007361269500346267\n",
      "Iteration [2349/4000]\tLoss: 0.08423653990030289\tLR: 0.007285595501349255\n",
      "Iteration [2359/4000]\tLoss: 0.08413837105035782\tLR: 0.007210088939607703\n",
      "Iteration [2369/4000]\tLoss: 0.08404164761304855\tLR: 0.0071347544727220135\n",
      "Iteration [2379/4000]\tLoss: 0.0839463621377945\tLR: 0.007059596747676957\n",
      "Iteration [2389/4000]\tLoss: 0.08385247737169266\tLR: 0.006984620400555039\n",
      "Iteration [2399/4000]\tLoss: 0.08376000076532364\tLR: 0.006909830056250522\n",
      "Start evaluating ...\n",
      "Val [2399/4000] Accuracy: 0.475 f1: 0.3494259363824581 Precision: 0.351984126984127 Recall: 0.3696969696969697 AUROC: 0.48427398989898984 AUPRC: 0.5813210102801353\n",
      "Iteration [2409/4000]\tLoss: 0.08366889506578445\tLR: 0.0068352303281841355\n",
      "Iteration [2419/4000]\tLoss: 0.0835791602730751\tLR: 0.006760825818018502\n",
      "Iteration [2429/4000]\tLoss: 0.0834907665848732\tLR: 0.006686621115374287\n",
      "Iteration [2439/4000]\tLoss: 0.08340369164943695\tLR: 0.006612620797547083\n",
      "Iteration [2449/4000]\tLoss: 0.08331794291734695\tLR: 0.006538829429225067\n",
      "Iteration [2459/4000]\tLoss: 0.08323346823453903\tLR: 0.006465251562207425\n",
      "Iteration [2469/4000]\tLoss: 0.08315029740333557\tLR: 0.006391891735123575\n",
      "Iteration [2479/4000]\tLoss: 0.08306838572025299\tLR: 0.006318754473153214\n",
      "Iteration [2489/4000]\tLoss: 0.0829877108335495\tLR: 0.006245844287747165\n",
      "Iteration [2499/4000]\tLoss: 0.0829082801938057\tLR: 0.006173165676349099\n",
      "Start evaluating ...\n",
      "Val [2499/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48427398989898984 AUPRC: 0.5813210102801353\n",
      "Best f1 increase from 0.3494259363824581 to 0.36688625384277557\n",
      "Iteration [2509/4000]\tLoss: 0.08283006399869919\tLR: 0.006100723122118116\n",
      "Iteration [2519/4000]\tLoss: 0.08275306224822998\tLR: 0.0060285210936521895\n",
      "Iteration [2529/4000]\tLoss: 0.08267723768949509\tLR: 0.005956564044712547\n",
      "Iteration [2539/4000]\tLoss: 0.0826025977730751\tLR: 0.0058848564139489115\n",
      "Iteration [2549/4000]\tLoss: 0.08252910524606705\tLR: 0.005813402624625717\n",
      "Iteration [2559/4000]\tLoss: 0.08245676755905151\tLR: 0.005742207084349273\n",
      "Iteration [2569/4000]\tLoss: 0.08238556981086731\tLR: 0.00567127418479586\n",
      "Iteration [2579/4000]\tLoss: 0.08231548219919205\tLR: 0.005600608301440847\n",
      "Iteration [2589/4000]\tLoss: 0.08224650472402573\tLR: 0.005530213793288789\n",
      "Iteration [2599/4000]\tLoss: 0.08217862993478775\tLR: 0.005460095002604531\n",
      "Start evaluating ...\n",
      "Val [2599/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48427398989898984 AUPRC: 0.5813210102801353\n",
      "Iteration [2609/4000]\tLoss: 0.08211183547973633\tLR: 0.005390256254645376\n",
      "Iteration [2619/4000]\tLoss: 0.08204609900712967\tLR: 0.005320701857394267\n",
      "Iteration [2629/4000]\tLoss: 0.08198142796754837\tLR: 0.0052514361012940556\n",
      "Iteration [2639/4000]\tLoss: 0.08191780000925064\tLR: 0.005182463258982851\n",
      "Iteration [2649/4000]\tLoss: 0.08185520023107529\tLR: 0.00511378758503045\n",
      "Iteration [2659/4000]\tLoss: 0.08179362118244171\tLR: 0.005045413315675925\n",
      "Iteration [2669/4000]\tLoss: 0.08173305541276932\tLR: 0.004977344668566275\n",
      "Iteration [2679/4000]\tLoss: 0.08167349547147751\tLR: 0.004909585842496288\n",
      "Iteration [2689/4000]\tLoss: 0.08161488175392151\tLR: 0.004842141017149528\n",
      "Iteration [2699/4000]\tLoss: 0.0815572738647461\tLR: 0.004775014352840513\n",
      "Start evaluating ...\n",
      "Val [2699/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5789850141532894\n",
      "Iteration [2709/4000]\tLoss: 0.08150060474872589\tLR: 0.0047082099902580965\n",
      "Iteration [2719/4000]\tLoss: 0.08144491165876389\tLR: 0.004641732050210036\n",
      "Iteration [2729/4000]\tLoss: 0.0813901424407959\tLR: 0.004575584633368815\n",
      "Iteration [2739/4000]\tLoss: 0.08133630454540253\tLR: 0.004509771820018684\n",
      "Iteration [2749/4000]\tLoss: 0.08128338307142258\tLR: 0.004444297669803979\n",
      "Iteration [2759/4000]\tLoss: 0.08123136311769485\tLR: 0.004379166221478689\n",
      "Iteration [2769/4000]\tLoss: 0.08118025958538055\tLR: 0.004314381492657356\n",
      "Iteration [2779/4000]\tLoss: 0.0811300203204155\tLR: 0.004249947479567212\n",
      "Iteration [2789/4000]\tLoss: 0.08108068257570267\tLR: 0.004185868156801693\n",
      "Iteration [2799/4000]\tLoss: 0.08103218674659729\tLR: 0.004122147477075268\n",
      "Start evaluating ...\n",
      "Val [2799/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5789850141532894\n",
      "Iteration [2809/4000]\tLoss: 0.08098455518484116\tLR: 0.004058789370979609\n",
      "Iteration [2819/4000]\tLoss: 0.08093776553869247\tLR: 0.003995797746741158\n",
      "Iteration [2829/4000]\tLoss: 0.08089181780815125\tLR: 0.003933176489980003\n",
      "Iteration [2839/4000]\tLoss: 0.08084669709205627\tLR: 0.0038709294634702344\n",
      "Iteration [2849/4000]\tLoss: 0.08080239593982697\tLR: 0.0038090605069016595\n",
      "Iteration [2859/4000]\tLoss: 0.08075889945030212\tLR: 0.0037475734366429446\n",
      "Iteration [2869/4000]\tLoss: 0.08071619272232056\tLR: 0.0036864720455062196\n",
      "Iteration [2879/4000]\tLoss: 0.08067428320646286\tLR: 0.003625760102513099\n",
      "Iteration [2889/4000]\tLoss: 0.08063315600156784\tLR: 0.0035654413526622084\n",
      "Iteration [2899/4000]\tLoss: 0.0805928036570549\tLR: 0.003505519516698162\n",
      "Start evaluating ...\n",
      "Val [2899/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5789850141532894\n",
      "Iteration [2909/4000]\tLoss: 0.08055318892002106\tLR: 0.0034459982908820594\n",
      "Iteration [2919/4000]\tLoss: 0.0805143490433693\tLR: 0.003386881346763477\n",
      "Iteration [2929/4000]\tLoss: 0.08047626167535782\tLR: 0.003328172330954\n",
      "Iteration [2939/4000]\tLoss: 0.08043888211250305\tLR: 0.0032698748649022664\n",
      "Iteration [2949/4000]\tLoss: 0.08040225505828857\tLR: 0.003211992544670583\n",
      "Iteration [2959/4000]\tLoss: 0.08036632090806961\tLR: 0.0031545289407131135\n",
      "Iteration [2969/4000]\tLoss: 0.08033113181591034\tLR: 0.0030974875976556263\n",
      "Iteration [2979/4000]\tLoss: 0.08029661327600479\tLR: 0.003040872034076854\n",
      "Iteration [2989/4000]\tLoss: 0.08026279509067535\tLR: 0.0029846857422914414\n",
      "Iteration [2999/4000]\tLoss: 0.08022964745759964\tLR: 0.0029289321881345236\n",
      "Start evaluating ...\n",
      "Val [2999/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.4792234848484848 AUPRC: 0.577662262830538\n",
      "Iteration [3009/4000]\tLoss: 0.08019720762968063\tLR: 0.002873614810747946\n",
      "Iteration [3019/4000]\tLoss: 0.08016541600227356\tLR: 0.0028187370223681117\n",
      "Iteration [3029/4000]\tLoss: 0.0801343023777008\tLR: 0.0027643022081155033\n",
      "Iteration [3039/4000]\tLoss: 0.08010382205247879\tLR: 0.0027103137257858826\n",
      "Iteration [3049/4000]\tLoss: 0.0800739973783493\tLR: 0.0026567749056431436\n",
      "Iteration [3059/4000]\tLoss: 0.08004478365182877\tLR: 0.002603689050213905\n",
      "Iteration [3069/4000]\tLoss: 0.08001623302698135\tLR: 0.002551059434083781\n",
      "Iteration [3079/4000]\tLoss: 0.07998828589916229\tLR: 0.0024988893036954033\n",
      "Iteration [3089/4000]\tLoss: 0.07996095716953278\tLR: 0.0024471818771481624\n",
      "Iteration [3099/4000]\tLoss: 0.0799342468380928\tLR: 0.0023959403439996886\n",
      "Start evaluating ...\n",
      "Val [3099/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.4792234848484848 AUPRC: 0.577662262830538\n",
      "Iteration [3109/4000]\tLoss: 0.0799081027507782\tLR: 0.002345167865069117\n",
      "Iteration [3119/4000]\tLoss: 0.07988256961107254\tLR: 0.0022948675722421073\n",
      "Iteration [3129/4000]\tLoss: 0.07985761761665344\tLR: 0.0022450425682776554\n",
      "Iteration [3139/4000]\tLoss: 0.07983323931694031\tLR: 0.0021956959266167014\n",
      "Iteration [3149/4000]\tLoss: 0.07980943471193314\tLR: 0.0021468306911925496\n",
      "Iteration [3159/4000]\tLoss: 0.07978618890047073\tLR: 0.002098449876243095\n",
      "Iteration [3169/4000]\tLoss: 0.0797634869813919\tLR: 0.002050556466124901\n",
      "Iteration [3179/4000]\tLoss: 0.07974135130643845\tLR: 0.0020031534151290966\n",
      "Iteration [3189/4000]\tLoss: 0.07971972972154617\tLR: 0.0019562436472991547\n",
      "Iteration [3199/4000]\tLoss: 0.07969865947961807\tLR: 0.001909830056250526\n",
      "Start evaluating ...\n",
      "Val [3199/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.4792234848484848 AUPRC: 0.577662262830538\n",
      "Iteration [3209/4000]\tLoss: 0.07967811077833176\tLR: 0.00186391550499213\n",
      "Iteration [3219/4000]\tLoss: 0.07965808361768723\tLR: 0.0018185028257497668\n",
      "Iteration [3229/4000]\tLoss: 0.07963855564594269\tLR: 0.0017735948197914024\n",
      "Iteration [3239/4000]\tLoss: 0.07961953431367874\tLR: 0.001729194257254383\n",
      "Iteration [3249/4000]\tLoss: 0.07960101217031479\tLR: 0.0016853038769745455\n",
      "Iteration [3259/4000]\tLoss: 0.07958298176527023\tLR: 0.0016419263863172964\n",
      "Iteration [3269/4000]\tLoss: 0.07956544309854507\tLR: 0.0015990644610105803\n",
      "Iteration [3279/4000]\tLoss: 0.07954835146665573\tLR: 0.0015567207449798488\n",
      "Iteration [3289/4000]\tLoss: 0.07953174412250519\tLR: 0.0015148978501849657\n",
      "Iteration [3299/4000]\tLoss: 0.07951560616493225\tLR: 0.001473598356459077\n",
      "Start evaluating ...\n",
      "Val [3299/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.4792234848484848 AUPRC: 0.577662262830538\n",
      "Iteration [3309/4000]\tLoss: 0.07949993014335632\tLR: 0.0014328248113495037\n",
      "Iteration [3319/4000]\tLoss: 0.07948470115661621\tLR: 0.0013925797299605637\n",
      "Iteration [3329/4000]\tLoss: 0.07946989685297012\tLR: 0.0013528655947984494\n",
      "Iteration [3339/4000]\tLoss: 0.07945552468299866\tLR: 0.0013136848556180882\n",
      "Iteration [3349/4000]\tLoss: 0.0794416144490242\tLR: 0.0012750399292720271\n",
      "Iteration [3359/4000]\tLoss: 0.07942809909582138\tLR: 0.001236933199561363\n",
      "Iteration [3369/4000]\tLoss: 0.07941500842571259\tLR: 0.0011993670170886794\n",
      "Iteration [3379/4000]\tLoss: 0.07940232753753662\tLR: 0.0011623436991130645\n",
      "Iteration [3389/4000]\tLoss: 0.0793900415301323\tLR: 0.0011258655294071676\n",
      "Iteration [3399/4000]\tLoss: 0.0793781504034996\tLR: 0.001089934758116321\n",
      "Start evaluating ...\n",
      "Val [3399/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5791774143456897\n",
      "Iteration [3409/4000]\tLoss: 0.07936664670705795\tLR: 0.0010545536016197466\n",
      "Iteration [3419/4000]\tLoss: 0.07935553044080734\tLR: 0.0010197242423938438\n",
      "Iteration [3429/4000]\tLoss: 0.07934480160474777\tLR: 0.0009854488288775435\n",
      "Iteration [3439/4000]\tLoss: 0.07933442294597626\tLR: 0.0009517294753398053\n",
      "Iteration [3449/4000]\tLoss: 0.07932441681623459\tLR: 0.0009185682617491874\n",
      "Iteration [3459/4000]\tLoss: 0.07931476831436157\tLR: 0.0008859672336455459\n",
      "Iteration [3469/4000]\tLoss: 0.07930545508861542\tLR: 0.0008539284020138624\n",
      "Iteration [3479/4000]\tLoss: 0.07929650694131851\tLR: 0.000822453743160187\n",
      "Iteration [3489/4000]\tLoss: 0.07928787916898727\tLR: 0.0007915451985897365\n",
      "Iteration [3499/4000]\tLoss: 0.0792795866727829\tLR: 0.000761204674887131\n",
      "Start evaluating ...\n",
      "Val [3499/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5791774143456897\n",
      "Iteration [3509/4000]\tLoss: 0.07927162200212479\tLR: 0.0007314340435987906\n",
      "Iteration [3519/4000]\tLoss: 0.07926396280527115\tLR: 0.000702235141117484\n",
      "Iteration [3529/4000]\tLoss: 0.07925662398338318\tLR: 0.0006736097685690587\n",
      "Iteration [3539/4000]\tLoss: 0.07924958318471909\tLR: 0.0006455596917013261\n",
      "Iteration [3549/4000]\tLoss: 0.07924284040927887\tLR: 0.0006180866407751581\n",
      "Iteration [3559/4000]\tLoss: 0.07923639565706253\tLR: 0.0005911923104577452\n",
      "Iteration [3569/4000]\tLoss: 0.07923023402690887\tLR: 0.0005648783597180626\n",
      "Iteration [3579/4000]\tLoss: 0.0792243480682373\tLR: 0.0005391464117245455\n",
      "Iteration [3589/4000]\tLoss: 0.07921873778104782\tLR: 0.0005139980537449524\n",
      "Iteration [3599/4000]\tLoss: 0.07921338081359863\tLR: 0.0004894348370484632\n",
      "Start evaluating ...\n",
      "Val [3599/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5791774143456897\n",
      "Iteration [3609/4000]\tLoss: 0.07920829951763153\tLR: 0.00046545827680998653\n",
      "Iteration [3619/4000]\tLoss: 0.07920345664024353\tLR: 0.00044206985201669744\n",
      "Iteration [3629/4000]\tLoss: 0.07919886708259583\tLR: 0.00041927100537680656\n",
      "Iteration [3639/4000]\tLoss: 0.07919452339410782\tLR: 0.0003970631432305681\n",
      "Iteration [3649/4000]\tLoss: 0.07919039577245712\tLR: 0.000375447635463527\n",
      "Iteration [3659/4000]\tLoss: 0.07918652892112732\tLR: 0.00035442581542201914\n",
      "Iteration [3669/4000]\tLoss: 0.07918284088373184\tLR: 0.00033399897983092745\n",
      "Iteration [3679/4000]\tLoss: 0.07917939126491547\tLR: 0.0003141683887136882\n",
      "Iteration [3689/4000]\tLoss: 0.07917613536119461\tLR: 0.00029493526531457437\n",
      "Iteration [3699/4000]\tLoss: 0.07917311042547226\tLR: 0.0002763007960232336\n",
      "Start evaluating ...\n",
      "Val [3699/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5791774143456897\n",
      "Iteration [3709/4000]\tLoss: 0.07917025685310364\tLR: 0.00025826613030150575\n",
      "Iteration [3719/4000]\tLoss: 0.07916758209466934\tLR: 0.000240832380612526\n",
      "Iteration [3729/4000]\tLoss: 0.07916510850191116\tLR: 0.00022400062235209333\n",
      "Iteration [3739/4000]\tLoss: 0.07916280627250671\tLR: 0.00020777189378234074\n",
      "Iteration [3749/4000]\tLoss: 0.079160675406456\tLR: 0.0001921471959676951\n",
      "Iteration [3759/4000]\tLoss: 0.0791587084531784\tLR: 0.0001771274927131122\n",
      "Iteration [3769/4000]\tLoss: 0.07915689796209335\tLR: 0.0001627137105046412\n",
      "Iteration [3779/4000]\tLoss: 0.07915521413087845\tLR: 0.00014890673845226093\n",
      "Iteration [3789/4000]\tLoss: 0.07915370166301727\tLR: 0.0001357074282350453\n",
      "Iteration [3799/4000]\tLoss: 0.07915231585502625\tLR: 0.00012311659404862306\n",
      "Start evaluating ...\n",
      "Val [3799/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5791774143456897\n",
      "Iteration [3809/4000]\tLoss: 0.07915106415748596\tLR: 0.00011113501255495451\n",
      "Iteration [3819/4000]\tLoss: 0.07914993911981583\tLR: 9.976342283442435e-05\n",
      "Iteration [3829/4000]\tLoss: 0.07914891839027405\tLR: 8.900252634025248e-05\n",
      "Iteration [3839/4000]\tLoss: 0.07914802432060242\tLR: 7.885298685522213e-05\n",
      "Iteration [3849/4000]\tLoss: 0.07914722710847855\tLR: 6.931543045073685e-05\n",
      "Iteration [3859/4000]\tLoss: 0.07914653420448303\tLR: 6.039044544820275e-05\n",
      "Iteration [3869/4000]\tLoss: 0.07914593070745468\tLR: 5.207858238273506e-05\n",
      "Iteration [3879/4000]\tLoss: 0.0791454091668129\tLR: 4.43803539691999e-05\n",
      "Iteration [3889/4000]\tLoss: 0.07914495468139648\tLR: 3.7296235070587314e-05\n",
      "Iteration [3899/4000]\tLoss: 0.07914458960294724\tLR: 3.082666266872025e-05\n",
      "Start evaluating ...\n",
      "Val [3899/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5791774143456897\n",
      "Iteration [3909/4000]\tLoss: 0.07914429157972336\tLR: 2.4972035837299478e-05\n",
      "Iteration [3919/4000]\tLoss: 0.07914403825998306\tLR: 1.973271571728434e-05\n",
      "Iteration [3929/4000]\tLoss: 0.07914386689662933\tLR: 1.5109025494620623e-05\n",
      "Iteration [3939/4000]\tLoss: 0.0791437104344368\tLR: 1.1101250380300927e-05\n",
      "Iteration [3949/4000]\tLoss: 0.07914359867572784\tLR: 7.709637592770966e-06\n",
      "Iteration [3959/4000]\tLoss: 0.07914355397224426\tLR: 4.934396342683983e-06\n",
      "Iteration [3969/4000]\tLoss: 0.07914353907108307\tLR: 2.7756978199944177e-06\n",
      "Iteration [3979/4000]\tLoss: 0.07914352416992188\tLR: 1.2336751833941185e-06\n",
      "Iteration [3989/4000]\tLoss: 0.07914352416992188\tLR: 3.0842355210336393e-07\n",
      "Iteration [3999/4000]\tLoss: 0.07914352416992188\tLR: 0.0\n",
      "Start evaluating ...\n",
      "Val [3999/4000] Accuracy: 0.48333333333333334 f1: 0.36688625384277557 Precision: 0.3630952380952381 Recall: 0.38821548821548824 AUROC: 0.48090698653198655 AUPRC: 0.5791774143456897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\workspace\\pathology\\gigapath\\code\\transfer\\gliopath\\train\\task\\gene.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'{output_dir}/best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5 f1: 0.33649732620320855 Precision: 0.3518518518518518 Recall: 0.4172619047619048 AUROC: 0.6525628306878306 AUPRC: 0.6921046204677156\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
