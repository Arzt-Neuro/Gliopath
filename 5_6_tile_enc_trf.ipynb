{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## cut images",
   "id": "4d5ce4e061ce53a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:23:53.984457Z",
     "start_time": "2025-09-21T13:23:53.956897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gliopath.utils.slicer import tile_slides\n",
    "import os\n",
    "os.chdir('F:/workspace/pathology/gigapath')"
   ],
   "id": "b6e6d1d33b6edc8c",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/workspace/pathology/gigapath'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgliopath\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mslicer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tile_slides\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchdir\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mD:/workspace/pathology/gigapath\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'D:/workspace/pathology/gigapath'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "slide_paths = ['model/sample_data/PROV-000-000001.ndpi',\n",
    "               'model/sample_data/PROV-000-000002.ndpi',\n",
    "               'model/sample_data/PROV-000-000003.ndpi']\n",
    "output_dir = 'output'"
   ],
   "id": "1766ab54f408c351"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tile_slides(slide_paths, save_dir=output_dir, level=1)",
   "id": "5b565372bb45e9f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## run tile inference model",
   "id": "ab8abdfc8248e15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gliopath.models.load import giga_tile_enc\n",
    "from gliopath.train.gadget import TileDataset\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "os.chdir('F:/workspace/pathology/gigapath')\n",
    "tile_encoder = giga_tile_enc(path='model/pub/')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tile_encoder = tile_encoder.cuda()\n",
    "tile_encoder.eval()\n",
    "batch_size = 128\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ])"
   ],
   "id": "69555a2f327e4c8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T13:46:16.090735Z",
     "start_time": "2025-09-21T13:46:16.054288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the folder names of folder with enough png files and csv files \n",
    "chemises_image = []\n",
    "\n",
    "for chemise_image in os.listdir('output/tiles/'):\n",
    "    n_csv = len([f for f in os.listdir('output/tiles/' + chemise_image) if f.lower().endswith('.csv')])\n",
    "    n_png = len([f for f in os.listdir('output/tiles/' + chemise_image) if f.lower().endswith('.png')])\n",
    "    if n_csv > (-1) and n_png > 0:\n",
    "        chemises_image.append('output/tiles/' + chemise_image + '/')"
   ],
   "id": "9112ac1726a768f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 使用 with torch.no_grad() 替代装饰器\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "        \n",
    "        for chemise_image in tqdm(chemises_image, desc='Slide Progress', leave=True):\n",
    "            tile_dl = DataLoader(TileDataset(glob(chemise_image + '*.png', recursive=False), transform=transform), batch_size=batch_size, shuffle=False)\n",
    "            tile_embeds = {'tile_embeds': [], 'coords': []}\n",
    "            \n",
    "            for batch in tqdm(tile_dl, desc=chemise_image, leave=False):\n",
    "                tile_embeds['tile_embeds'].append(tile_encoder(batch['img'].cuda()).detach().cpu())\n",
    "                tile_embeds['coords'].append(batch['coords'])\n",
    "\n",
    "            slide_embeds = {k: torch.cat(v) for k, v in tile_embeds.items()}\n",
    "            torch.save(slide_embeds, 'output/tiles/' + chemise_image + '.pt')"
   ],
   "id": "b9cb67fb33cfe438"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## [note] this script file does not contain tile encoder fine-tuning",
   "id": "7c2e04a6d88dec4c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
